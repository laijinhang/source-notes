调度器，所有 Goroutine 被调度的核心，存放了调度器持有的全局资源，访问这些资源需要持有锁：
* 管理了能够将G和M进行绑定的M队列
* 管理了空闲的P链表（队列）
* 管理了G的全局队列
* 管理了可被复用的G的全局缓存
* 管理了defer池
# 一、结构
### 1. 数据结构
```go
/*
调度器sched结构
*/
type schedt struct {
   // accessed atomically. keep at top to ensure alignment on 32-bit systems.
   // 在32位系统上保持在顶部以确保对齐。
   /*
       Sched.goidgen 用于为最后（最新创建）一个goroutine分配的id（goid），相当于一个全局计数器
       启动时 sched.goidgen=0，因此主 Goroutine 的goid为1
   */
   goidgen uint64
   /*
       最后一次网络轮询的时间，如果目前正在轮询则为0
   */
   lastpoll uint64 // time of last network poll, 0 if currently polling
   /*
       当前轮询的睡眠时间
   */
   pollUntil uint64 // time to which current poll is sleeping
   
   lock mutex
   
   // When increasing nmidle, nmidlelocked, nmsys, or nmfreed, be
   // sure to call checkdead().
   // 在增加nmidle、nmidlelocked、nmsys或nmfreed时，一定要调用checkdead()。
   
   // 空闲的 M 列表
   midle muintptr // idle m's waiting for work
   // 空闲的 M 列表数量
   nmidle int32 // number of idle m's waiting for work
   // lockde状态的m个数
   nmidlelocked int32 // number of locked m's waiting for work
   // 下一个被创建的 M 的 id
   mnext int64 // number of m's that have been created and next M ID
   // 表示最多所能创建的工作线程数量
   maxmcount int32 // maximum number of m's allowed (or die)
   // 不计入死锁的系统M的数量
   nmsys int32 // number of system m's not counted for deadlock
   // 累计释放的M的数量（空闲m的数量）
   nmfreed int64 // cumulative number of freed m's
   
   // 系统中goroutine的数目，会自动更新
   ngsys uint32 // number of system goroutines; updated atomically
   
   pidle  puintptr // idle p's	// 空闲p链表
   npidle uint32   // 空闲p数量
   // 自旋状态的M的数量
   nmspinning uint32 // See "Worker thread parking/unparking" comment in proc.go.
   
   // Global runnable queue.
   // 全局 runnable G 队列
   runq     gQueue
   runqsize int32
   
   // disable controls selective disabling of the scheduler.
   //
   // Use schedEnableUser to control this.
   //
   // disable is protected by sched.lock.
   disable struct {
      // user disables scheduling of user goroutines.
      user     bool
      runnable gQueue // pending runnable Gs
      n        int32  // length of runnable
   }
   
   // Global cache of dead G's.
   // 有效 dead G 的全局缓存。
   gFree struct {
      lock    mutex
      stack   gList // Gs with stacks		// 包含栈的Gs
      noStack gList // Gs without stacks	// 没有栈的Gs
      n       int32
   }
   
   // Central cache of sudog structs.
   // sudog 结构中的集中缓存
   sudoglock  mutex
   sudogcache *sudog
   
   // Central pool of available defer structs of different sizes.
   // 不同大小的有效 defer 结构的池
   deferlock mutex
   deferpool [5]*_defer
   
   // freem is the list of m's waiting to be freed when their
   // m.exited is set. Linked through m.freelink.
   freem *m
   
   /*
       gcwaiting标志
   
       startTheWorld的时候，会将gcwaiting设为0，表示表示gc正在等待运行？？？
       stopTheWorld的时候，会将gcwaiting设为1，表示gc正在运行？？？
   */
   gcwaiting uint32 // gc is waiting to run
   
   stopwait   int32
   stopnote   note
   sysmonwait uint32
   sysmonnote note
   
   // While true, sysmon not ready for mFixup calls.
   // Accessed atomically.
   sysmonStarting uint32
   
   // safepointFn should be called on each P at the next GC
   // safepoint if p.runSafePointFn is set.
   safePointFn   func(*p)
   safePointWait int32
   safePointNote note
   
   profilehz int32 // cpu profiling rate
   
   /*
       上次修改 gomaxprocs 的纳秒时间
   */
   procresizetime int64 // nanotime() of last change to gomaxprocs
   totaltime      int64 // ∫gomaxprocs dt up to procresizetime
   
   // sysmonlock protects sysmon's actions on the runtime.
   //
   // Acquire and hold this mutex to block sysmon from interacting
   // with the rest of the runtime.
   sysmonlock mutex
   
   _ uint32 // ensure timeToRun has 8-byte alignment
   
   // timeToRun is a distribution of scheduling latencies, defined
   // as the sum of time a G spends in the _Grunnable state before
   // it transitions to _Grunning.
   // timeToRun是一个调度延迟的分布，定义为一个G在过渡到_Grunnable状态之前在
   // _Grunning状态下花费的时间总和。
   //
   // timeToRun is protected by sched.lock.
   // timeToRun受到sched.lock的保护。
   timeToRun timeHistogram
}
```
### 2. 状态
# 二、工作原理
### 1. 初始化
```go
func schedinit() {
	lockInit(&sched.lock, lockRankSched)
	lockInit(&sched.sysmonlock, lockRankSysmon)
	lockInit(&sched.deferlock, lockRankDefer)
	lockInit(&sched.sudoglock, lockRankSudog)
	lockInit(&deadlock, lockRankDeadlock)
	lockInit(&paniclk, lockRankPanic)
	lockInit(&allglock, lockRankAllg)
	lockInit(&allpLock, lockRankAllp)
	lockInit(&reflectOffs.lock, lockRankReflectOffs)
	lockInit(&finlock, lockRankFin)
	lockInit(&trace.bufLock, lockRankTraceBuf)
	lockInit(&trace.stringsLock, lockRankTraceStrings)
	lockInit(&trace.lock, lockRankTrace)
	lockInit(&cpuprof.lock, lockRankCpuprof)
	lockInit(&trace.stackTab.lock, lockRankTraceStackTab)
	// Enforce that this lock is always a leaf lock.
	// All of this lock's critical sections should be
	// extremely short.
	lockInit(&memstats.heapStats.noPLock, lockRankLeafRank)

	// raceinit must be the first call to race detector.
	// In particular, it must be done before mallocinit below calls racemapshadow.
	_g_ := getg()
	if raceenabled {
		_g_.racectx, raceprocctx0 = raceinit()
	}

	// M（线程）最大数量限制
	sched.maxmcount = 10000

	// The world starts stopped.
	worldStopped()

	moduledataverify()
	stackinit()    // 栈初始化
	mallocinit()   // 内存初始化
	fastrandinit() // must run before mcommoninit
	// M 初始化
	mcommoninit(_g_.m, -1)
	cpuinit()       // must run before alginit
	alginit()       // maps must not be used before this call
	modulesinit()   // provides activeModules
	typelinksinit() // uses maps, activeModules
	itabsinit()     // uses activeModules

	sigsave(&_g_.m.sigmask)
	initSigmask = _g_.m.sigmask

	if offset := unsafe.Offsetof(sched.timeToRun); offset%8 != 0 {
		println(offset)
		throw("sched.timeToRun not aligned to 8 bytes")
	}

	goargs()
	goenvs()
	parsedebugvars()
	// 垃圾回收器初始化
	gcinit()

	lock(&sched.lock)
	// 设置最后一次轮询时间
	sched.lastpoll = uint64(nanotime())
	// 通过 CPU 核心数 和 GOMAPROCS 环境变量确定 P 的数量
	// 设置GOMAXPROCS
	procs := ncpu
	if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok && n > 0 {
		procs = n
	}
	// P 初始化
	if procresize(procs) != nil {
		throw("unknown runnable goroutine during bootstrap")
	}
	unlock(&sched.lock)

	// World is effectively started now, as P's can run.
	worldStarted()

	// For cgocheck > 1, we turn on the write barrier at all times
	// and check all pointer writes. We can't do this until after
	// procresize because the write barrier needs a P.
	if debug.cgocheck > 1 {
		writeBarrier.cgo = true
		writeBarrier.enabled = true
		for _, p := range allp {
			p.wbBuf.reset()
		}
	}

	if buildVersion == "" {
		// Condition should never trigger. This code just serves
		// to ensure runtime·buildVersion is kept in the resulting binary.
		buildVersion = "unknown"
	}
	if len(modinfo) == 1 {
		// Condition should never trigger. This code just serves
		// to ensure runtime·modinfo is kept in the resulting binary.
		modinfo = ""
	}
}
```
### 1. 协程切换
runtime/proc.go

gopack用于协程的切换，协程切换的原因一般有以下几种情况：
1. 系统调用
2. channel读写条件不满足
3. 抢占式调度时间片结束
   gopack函数做的主要事情分为两点：
1. 解除当前goroutine与m的绑定关闭，将当前goroutine状态机切换为等待状态；
2. 调用一次schedule()函数，在局部调度器P发起一轮新的调度。
```go
func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {
	if reason != waitReasonSleep {
		checkTimeouts() // timeouts may expire while two goroutines keep the scheduler busy
	}
	mp := acquirem()
	gp := mp.curg
	status := readgstatus(gp)

	if status != _Grunning && status != _Gscanrunning {
		throw("gopark: bad g status")
	}
	mp.waitlock = lock
	mp.waitunlockf = unlockf
	gp.waitreason = reason
	mp.waittraceev = traceEv
	mp.waittraceskip = traceskip
	releasem(mp)
	// can't do anything that might move the G between Ms here.
	/*
		协程切换工作：
		1. 切换当前线程的堆栈从g的堆栈切换到g0的堆栈；
		2. 并在g0的堆栈上执行新的函数fn(g)；
		3. 保存当前协程的信息（PC/SP存储到g->sched)，当后续对当前协程调用Goready函数时候能够恢复现场；
		mcall函数是通过汇编实现的，64位机的实现代码在 asm_amd64.s
		它将当前正在执行的协程状态保存起来，然后在m->g0的堆栈上调用新的函数。在新的函数内会将之前运行的协程放弃，
		然后调用一次schedule()来挑选新的协程运行（也就是在传入的函数中调用一次schedule()函数进行一次schedule的重新调度，
		让m去运行其余的goroutine）。
	*/
	mcall(park_m)
}
```